{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tmID</th>\n",
       "      <th>confID</th>\n",
       "      <th>rank</th>\n",
       "      <th>playoff</th>\n",
       "      <th>firstRound</th>\n",
       "      <th>semis</th>\n",
       "      <th>finals</th>\n",
       "      <th>o_fgm</th>\n",
       "      <th>o_fga</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_player_weight</th>\n",
       "      <th>avg_player_efficiency</th>\n",
       "      <th>avg_player_award_points</th>\n",
       "      <th>avg_player_last_3_years_sum_awards</th>\n",
       "      <th>avg_player_all_time_sum_awards</th>\n",
       "      <th>avg_player_age</th>\n",
       "      <th>last_year_avg_player_efficiency</th>\n",
       "      <th>stint_coach</th>\n",
       "      <th>award_points_coach</th>\n",
       "      <th>mean_wins_coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EA</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>895</td>\n",
       "      <td>2258</td>\n",
       "      <td>...</td>\n",
       "      <td>173.333333</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>24.833333</td>\n",
       "      <td>0.284286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1089</td>\n",
       "      <td>2428</td>\n",
       "      <td>...</td>\n",
       "      <td>173.583333</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>0.256364</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CHA</td>\n",
       "      <td>EA</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>1903</td>\n",
       "      <td>...</td>\n",
       "      <td>169.181818</td>\n",
       "      <td>0.253636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.636364</td>\n",
       "      <td>0.242222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>CHA</td>\n",
       "      <td>EA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>L</td>\n",
       "      <td>746</td>\n",
       "      <td>1780</td>\n",
       "      <td>...</td>\n",
       "      <td>175.166667</td>\n",
       "      <td>0.231667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>0.282857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>CHA</td>\n",
       "      <td>EA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>770</td>\n",
       "      <td>1790</td>\n",
       "      <td>...</td>\n",
       "      <td>166.666667</td>\n",
       "      <td>0.209333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.133333</td>\n",
       "      <td>0.220909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year tmID confID  rank  playoff firstRound semis finals  o_fgm  o_fga  ...  \\\n",
       "0     9  ATL     EA     7        0          0     0      0    895   2258  ...   \n",
       "1    10  ATL     EA     2        1          L     0      0   1089   2428  ...   \n",
       "2     1  CHA     EA     8        0          0     0      0    812   1903  ...   \n",
       "3     2  CHA     EA     4        1          W     W      L    746   1780  ...   \n",
       "4     3  CHA     EA     2        1          L     0      0    770   1790  ...   \n",
       "\n",
       "   avg_player_weight  avg_player_efficiency  avg_player_award_points  \\\n",
       "0         173.333333               0.243333                      0.0   \n",
       "1         173.583333               0.238333                      0.0   \n",
       "2         169.181818               0.253636                      0.0   \n",
       "3         175.166667               0.231667                      0.0   \n",
       "4         166.666667               0.209333                      0.0   \n",
       "\n",
       "   avg_player_last_3_years_sum_awards  avg_player_all_time_sum_awards  \\\n",
       "0                                 3.5                             3.5   \n",
       "1                                 3.5                             3.5   \n",
       "2                                 0.0                             0.0   \n",
       "3                                 0.0                             0.0   \n",
       "4                                 0.0                             0.0   \n",
       "\n",
       "   avg_player_age  last_year_avg_player_efficiency  stint_coach  \\\n",
       "0       24.833333                         0.284286            0   \n",
       "1       25.250000                         0.256364            0   \n",
       "2       26.636364                         0.242222            0   \n",
       "3       26.166667                         0.282857            0   \n",
       "4       25.133333                         0.220909            0   \n",
       "\n",
       "   award_points_coach  mean_wins_coach  \n",
       "0                 0.0         0.133333  \n",
       "1                 1.0         1.000000  \n",
       "2                 0.0         0.333333  \n",
       "3                 0.0         1.222222  \n",
       "4                 0.0         1.125000  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/clean/merged.csv\")\n",
    "#df = pd.read_csv(\"../data/clean/teams.csv\") # TESTING\n",
    "\n",
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "df[\"playoff\"] = df[\"playoff\"].map({\"Y\": 1, \"N\": 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmID Mapping: {'ATL': 0, 'CHA': 1, 'CHI': 2, 'CLE': 3, 'CON': 4, 'DET': 5, 'HOU': 6, 'IND': 7, 'LAS': 8, 'MIA': 9, 'MIN': 10, 'NYL': 11, 'ORL': 12, 'PHO': 13, 'POR': 14, 'SAC': 15, 'SAS': 16, 'SEA': 17, 'UTA': 18, 'WAS': 19}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_df(df):\n",
    "    le = LabelEncoder()\n",
    "    tmID_mapping = {} \n",
    "    \n",
    "    for col, col_type in df.dtypes.items():\n",
    "        if col_type == 'object' or col_type == 'datetime64[ns]':\n",
    "            # store mapping if the column is 'tmID'\n",
    "            if col == 'tmID':\n",
    "                df[col] = le.fit_transform(df[col])\n",
    "                tmID_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            else:\n",
    "                df[col] = le.fit_transform(df[col])\n",
    "                \n",
    "    return df, tmID_mapping\n",
    "\n",
    "# Use the function to encode the dataframe and get the tmID mapping\n",
    "df, tmID_mapping = encode_df(df)\n",
    "\n",
    "\n",
    "df.head( 10)\n",
    "print(\"tmID Mapping:\", tmID_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min year: 2 \n",
      "Max year: 10\n",
      "\n",
      "Train/Test size for year=2: (17, 60) (18, 60) (17,) (18,)\n",
      "\n",
      "AUC for year=2: 0.95\n",
      "Accuracy for year=2: 0.8888888888888888\n",
      "Precision for year=2: 0.8333333333333334\n",
      "\n",
      "Train/Test size for year=3: (35, 60) (19, 60) (35,) (19,)\n",
      "\n",
      "AUC for year=3: 0.9204545454545454\n",
      "Accuracy for year=3: 0.8421052631578947\n",
      "Precision for year=3: 0.7777777777777778\n",
      "\n",
      "Train/Test size for year=4: (54, 60) (16, 60) (54,) (16,)\n",
      "\n",
      "AUC for year=4: 0.8095238095238095\n",
      "Accuracy for year=4: 0.6875\n",
      "Precision for year=4: 0.7\n",
      "\n",
      "Train/Test size for year=5: (70, 60) (17, 60) (70,) (17,)\n",
      "\n",
      "AUC for year=5: 0.9090909090909091\n",
      "Accuracy for year=5: 0.7647058823529411\n",
      "Precision for year=5: 0.8888888888888888\n",
      "\n",
      "Train/Test size for year=6: (87, 60) (15, 60) (87,) (15,)\n",
      "\n",
      "AUC for year=6: 0.8518518518518519\n",
      "Accuracy for year=6: 0.7333333333333333\n",
      "Precision for year=6: 0.7777777777777778\n",
      "\n",
      "Train/Test size for year=7: (102, 60) (15, 60) (102,) (15,)\n",
      "\n",
      "AUC for year=7: 0.9464285714285715\n",
      "Accuracy for year=7: 0.8\n",
      "Precision for year=7: 1.0\n",
      "\n",
      "Train/Test size for year=8: (117, 60) (14, 60) (117,) (14,)\n",
      "\n",
      "AUC for year=8: 0.9583333333333334\n",
      "Accuracy for year=8: 0.6428571428571429\n",
      "Precision for year=8: 1.0\n",
      "\n",
      "Train/Test size for year=9: (131, 60) (15, 60) (131,) (15,)\n",
      "\n",
      "AUC for year=9: 0.9107142857142857\n",
      "Accuracy for year=9: 0.7333333333333333\n",
      "Precision for year=9: 0.75\n",
      "\n",
      "Train/Test size for year=10: (146, 60) (16, 60) (146,) (16,)\n",
      "\n",
      "AUC for year=10: 0.9523809523809523\n",
      "Accuracy for year=10: 0.9375\n",
      "Precision for year=10: 1.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_distribution_similarity(df, y_train, y_test):\n",
    "    # Step 1: Calculate class distribution in the original dataset\n",
    "    original_class_distribution = df['playoff'].value_counts(normalize=True)\n",
    "    print(\"Original Class Distribution:\")\n",
    "    print(original_class_distribution)\n",
    "\n",
    "    # Step 2: Calculate class distribution in the training and test sets\n",
    "    train_class_distribution = y_train.value_counts(normalize=True)\n",
    "    test_class_distribution = y_test.value_counts(normalize=True)\n",
    "\n",
    "    print(\"\\nTraining Set Class Distribution:\")\n",
    "    print(train_class_distribution)\n",
    "    print(\"\\nTest Set Class Distribution:\")\n",
    "    print(test_class_distribution)\n",
    "\n",
    "    # Step 3: Compare class distributions\n",
    "    class_distribution_similarity = (train_class_distribution - test_class_distribution).abs().sum()\n",
    "    print(\"\\nClass Distribution Similarity Score:\", class_distribution_similarity)\n",
    "\n",
    "    return class_distribution_similarity\n",
    "\n",
    "# Update the train_model function to include imputation\n",
    "def train_model(df, year):\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    teams_df_train = df[df['year'] < year]\n",
    "    teams_df_test = df[df['year'] == year]\n",
    "\n",
    "    X_train = teams_df_train.drop(\"playoff\", axis=1)  # Features\n",
    "    y_train = teams_df_train[\"playoff\"]  # Target variable\n",
    "\n",
    "    X_test = teams_df_test.drop(\"playoff\", axis=1)  # Features\n",
    "    y_test = teams_df_test[\"playoff\"]  # Target variable\n",
    "\n",
    "    print(f\"\\nTrain/Test size for year={year}:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# create a final dataset with the predictions: team, playoff, prediction (a probability between 0 and 1)\n",
    "def create_predictions(df, year, model, distribution_similarity=True):\n",
    "    # Create a copy of the original dataset\n",
    "    new_df = df.copy()\n",
    "\n",
    "    X_train, y_train, X_test, y_test = train_model(new_df, year)\n",
    "\n",
    "    # Check if the class distribution is similar between the training and test sets\n",
    "    if distribution_similarity:\n",
    "        calculate_class_distribution_similarity(new_df, y_train, y_test)    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test) # Predictions\n",
    "    y_pred_proba = model.predict_proba(X_test) # Prediction probabilities\n",
    "\n",
    "    # Calculate the AUC\n",
    "    auc = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "    print(f\"\\nAUC for year={year}:\", auc)\n",
    " \n",
    "     # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for year={year}: {accuracy}\")\n",
    "    \n",
    "    # Calculate Precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f\"Precision for year={year}: {precision}\")\n",
    "\n",
    "    \n",
    "    # Only add predictions to the test set\n",
    "    new_df.loc[new_df['year'] == year, 'prediction'] = y_pred\n",
    "    new_df.loc[new_df['year'] == year, 'prediction_proba'] = y_pred_proba[:,1]\n",
    "\n",
    "    # Filter the dataset to only include the year we are interested in\n",
    "    new_df = new_df[new_df['year'] == year]\n",
    "\n",
    "    # Convert the predictions to integers\n",
    "    new_df['prediction'] = new_df['prediction'].astype(int)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "min_year = df['year'].min() + 1\n",
    "max_year = df['year'].max()\n",
    "\n",
    "print(\"Min year:\", min_year, \"\\nMax year:\", max_year)\n",
    "\n",
    "\n",
    "def create_final_predictions(df, year):\n",
    "    # Select the best 4 teams for each conference (confID) ensuring unique teams\n",
    "    final_predictions = df[df['year'] == year].sort_values(by='prediction_proba', ascending=False).drop_duplicates(subset='tmID').groupby('confID').head(4)\n",
    "\n",
    "    # remove confID column\n",
    "    final_predictions.drop(['year', 'playoff', 'confID'], axis=1, inplace=True)\n",
    "\n",
    "    return final_predictions\n",
    "\n",
    "# Usage of the function within the loop\n",
    "for i in range(min_year, max_year + 1):\n",
    "    new_df = create_predictions(df, i, model, distribution_similarity=False)\n",
    "    new_df = create_final_predictions(new_df, i)\n",
    "    new_df.drop(new_df.columns.difference(['tmID', 'confID', 'year', 'playoff', 'prediction', 'prediction_proba']), axis=1, inplace=True)\n",
    "    new_df.to_csv(f\"../data/predictions/predictions_{i}.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
