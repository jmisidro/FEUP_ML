{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean/teams.csv\")\n",
    "\n",
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "df[\"playoff\"] = df[\"playoff\"].map({\"Y\": 1, \"N\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical(df, col):\n",
    "    values = df[col].unique()\n",
    "    mapping = {value: i for i, value in enumerate(values)}\n",
    "    df[col] = df[col].map(mapping)\n",
    "    return df\n",
    "\n",
    "df.fillna(-1, inplace=True)\n",
    "df = process_categorical(df, \"tmID\")\n",
    "df = process_categorical(df, \"confID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min year: 2 \n",
      "Max year: 10\n",
      "\n",
      "Train/Test size for year=2: (16, 5) (16, 5) (16,) (16,)\n",
      "\n",
      "year = 2, Accuracy: 0.4375\n",
      "\n",
      "year = 2, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47         8\n",
      "           1       0.43      0.38      0.40         8\n",
      "\n",
      "    accuracy                           0.44        16\n",
      "   macro avg       0.44      0.44      0.44        16\n",
      "weighted avg       0.44      0.44      0.44        16\n",
      "\n",
      "\n",
      "year = 2, Confusion Matrix:\n",
      " [[4 4]\n",
      " [5 3]]\n",
      "\n",
      "Train/Test size for year=3: (32, 5) (16, 5) (32,) (16,)\n",
      "\n",
      "year = 3, Accuracy: 0.5\n",
      "\n",
      "year = 3, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33         8\n",
      "           1       0.50      0.75      0.60         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.50      0.50      0.47        16\n",
      "weighted avg       0.50      0.50      0.47        16\n",
      "\n",
      "\n",
      "year = 3, Confusion Matrix:\n",
      " [[2 6]\n",
      " [2 6]]\n",
      "\n",
      "Train/Test size for year=4: (48, 5) (14, 5) (48,) (14,)\n",
      "\n",
      "year = 4, Accuracy: 0.35714285714285715\n",
      "\n",
      "year = 4, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.33      0.31         6\n",
      "           1       0.43      0.38      0.40         8\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.36      0.35      0.35        14\n",
      "weighted avg       0.37      0.36      0.36        14\n",
      "\n",
      "\n",
      "year = 4, Confusion Matrix:\n",
      " [[2 4]\n",
      " [5 3]]\n",
      "\n",
      "Train/Test size for year=5: (62, 5) (13, 5) (62,) (13,)\n",
      "\n",
      "year = 5, Accuracy: 0.38461538461538464\n",
      "\n",
      "year = 5, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33         5\n",
      "           1       0.50      0.38      0.43         8\n",
      "\n",
      "    accuracy                           0.38        13\n",
      "   macro avg       0.39      0.39      0.38        13\n",
      "weighted avg       0.42      0.38      0.39        13\n",
      "\n",
      "\n",
      "year = 5, Confusion Matrix:\n",
      " [[2 3]\n",
      " [5 3]]\n",
      "\n",
      "Train/Test size for year=6: (75, 5) (13, 5) (75,) (13,)\n",
      "\n",
      "year = 6, Accuracy: 0.46153846153846156\n",
      "\n",
      "year = 6, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.20      0.22         5\n",
      "           1       0.56      0.62      0.59         8\n",
      "\n",
      "    accuracy                           0.46        13\n",
      "   macro avg       0.40      0.41      0.41        13\n",
      "weighted avg       0.44      0.46      0.45        13\n",
      "\n",
      "\n",
      "year = 6, Confusion Matrix:\n",
      " [[1 4]\n",
      " [3 5]]\n",
      "\n",
      "Train/Test size for year=7: (88, 5) (14, 5) (88,) (14,)\n",
      "\n",
      "year = 7, Accuracy: 0.7857142857142857\n",
      "\n",
      "year = 7, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.79      0.77      0.78        14\n",
      "weighted avg       0.79      0.79      0.78        14\n",
      "\n",
      "\n",
      "year = 7, Confusion Matrix:\n",
      " [[4 2]\n",
      " [1 7]]\n",
      "\n",
      "Train/Test size for year=8: (102, 5) (13, 5) (102,) (13,)\n",
      "\n",
      "year = 8, Accuracy: 0.3076923076923077\n",
      "\n",
      "year = 8, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.20      0.18         5\n",
      "           1       0.43      0.38      0.40         8\n",
      "\n",
      "    accuracy                           0.31        13\n",
      "   macro avg       0.30      0.29      0.29        13\n",
      "weighted avg       0.33      0.31      0.32        13\n",
      "\n",
      "\n",
      "year = 8, Confusion Matrix:\n",
      " [[1 4]\n",
      " [5 3]]\n",
      "\n",
      "Train/Test size for year=9: (115, 5) (14, 5) (115,) (14,)\n",
      "\n",
      "year = 9, Accuracy: 0.5714285714285714\n",
      "\n",
      "year = 9, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         6\n",
      "           1       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.56      0.56      0.56        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "\n",
      "year = 9, Confusion Matrix:\n",
      " [[3 3]\n",
      " [3 5]]\n",
      "\n",
      "Train/Test size for year=10: (129, 5) (13, 5) (129,) (13,)\n",
      "\n",
      "year = 10, Accuracy: 0.6923076923076923\n",
      "\n",
      "year = 10, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.70      0.71      0.69        13\n",
      "weighted avg       0.73      0.69      0.70        13\n",
      "\n",
      "\n",
      "year = 10, Confusion Matrix:\n",
      " [[4 1]\n",
      " [3 5]]\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "min_year = 2\n",
    "max_year = df['year'].max()\n",
    "\n",
    "print(\"Min year:\", min_year, \"\\nMax year:\", max_year)\n",
    "\n",
    "for i in range(min_year, max_year + 1):\n",
    "    teams_df_train = df[df['year'] < i]\n",
    "    teams_df_test = df[df['year'] == i]\n",
    "\n",
    "    X_train = teams_df_train.drop(\"playoff\", axis=1) # Features\n",
    "    y_train = teams_df_train[\"playoff\"] # Target variable\n",
    "\n",
    "    X_test = teams_df_test.drop(\"playoff\", axis=1) # Features\n",
    "    y_test = teams_df_test[\"playoff\"] # Target variable\n",
    "\n",
    "    print(f\"\\nTrain/Test size for year={i}:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nyear = {i}, Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(f\"\\nyear = {i}, Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(f\"\\nyear = {i}, Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
