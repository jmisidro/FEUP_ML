{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean/merged.csv\")\n",
    "#df = pd.read_csv(\"../data/clean/teams.csv\") # TESTING\n",
    "\n",
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "df[\"playoff\"] = df[\"playoff\"].map({\"Y\": 1, \"N\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>award_points</th>\n",
       "      <th>last_3_years_sum</th>\n",
       "      <th>all_time_sum</th>\n",
       "      <th>tmID</th>\n",
       "      <th>pl_efficiency</th>\n",
       "      <th>confID</th>\n",
       "      <th>playoff</th>\n",
       "      <th>tm_efficiency</th>\n",
       "      <th>avg_height</th>\n",
       "      <th>avg_weight</th>\n",
       "      <th>avg_pl_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11.97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2837.48</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>156.666667</td>\n",
       "      <td>25.1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>19.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5048.57</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>162.500000</td>\n",
       "      <td>18.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2174.01</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>16.5075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>18.13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34146.05</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>14.9040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>15.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9824.61</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>160.333333</td>\n",
       "      <td>15.1700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  award_points  last_3_years_sum  all_time_sum  tmID  pl_efficiency  \\\n",
       "0     1           0.0                 0             0     6          11.97   \n",
       "1     2           6.0                 6             6     6          19.88   \n",
       "2     3           0.0                 6             6     6          16.60   \n",
       "3     4           0.0                 6             6     6          18.13   \n",
       "4     6           0.0                 0             6     6          15.10   \n",
       "\n",
       "   confID  playoff  tm_efficiency  avg_height  avg_weight  avg_pl_efficiency  \n",
       "0       1        1        2837.48   72.333333  156.666667            25.1625  \n",
       "1       1        1       -5048.57   72.500000  162.500000            18.0250  \n",
       "2       1        1       -2174.01   73.500000  157.000000            16.5075  \n",
       "3       1        1       34146.05   73.500000  157.000000            14.9040  \n",
       "4       1        1       -9824.61   72.333333  160.333333            15.1700  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_df(df):\n",
    "    le = LabelEncoder()\n",
    "    for col, col_type in df.dtypes.items():\n",
    "        if col_type == 'object' or col_type == 'datetime64[ns]':\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "df = encode_df(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min year: 2 \n",
      "Max year: 10\n",
      "\n",
      "Train/Test size for year=2: (21, 11) (26, 11) (21,) (26,)\n",
      "\n",
      "AUC for year=2: 0.5\n",
      "\n",
      "Train/Test size for year=3: (47, 11) (34, 11) (47,) (34,)\n",
      "\n",
      "AUC for year=3: 0.9792387543252594\n",
      "\n",
      "Train/Test size for year=4: (81, 11) (36, 11) (81,) (36,)\n",
      "\n",
      "AUC for year=4: 0.4307692307692308\n",
      "\n",
      "Train/Test size for year=5: (117, 11) (35, 11) (117,) (35,)\n",
      "\n",
      "AUC for year=5: 0.5641025641025641\n",
      "\n",
      "Train/Test size for year=6: (152, 11) (37, 11) (152,) (37,)\n",
      "\n",
      "AUC for year=6: 0.9761904761904762\n",
      "\n",
      "Train/Test size for year=7: (189, 11) (34, 11) (189,) (34,)\n",
      "\n",
      "AUC for year=7: 0.5178571428571428\n",
      "\n",
      "Train/Test size for year=8: (223, 11) (33, 11) (223,) (33,)\n",
      "\n",
      "AUC for year=8: 0.6942148760330578\n",
      "\n",
      "Train/Test size for year=9: (256, 11) (34, 11) (256,) (34,)\n",
      "\n",
      "AUC for year=9: 0.49242424242424243\n",
      "\n",
      "Train/Test size for year=10: (290, 11) (38, 11) (290,) (38,)\n",
      "\n",
      "AUC for year=10: 0.9078341013824885\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_distribution_similarity(df, y_train, y_test):\n",
    "    # Step 1: Calculate class distribution in the original dataset\n",
    "    original_class_distribution = df['playoff'].value_counts(normalize=True)\n",
    "    print(\"Original Class Distribution:\")\n",
    "    print(original_class_distribution)\n",
    "\n",
    "    # Step 2: Calculate class distribution in the training and test sets\n",
    "    train_class_distribution = y_train.value_counts(normalize=True)\n",
    "    test_class_distribution = y_test.value_counts(normalize=True)\n",
    "\n",
    "    print(\"\\nTraining Set Class Distribution:\")\n",
    "    print(train_class_distribution)\n",
    "    print(\"\\nTest Set Class Distribution:\")\n",
    "    print(test_class_distribution)\n",
    "\n",
    "    # Step 3: Compare class distributions\n",
    "    class_distribution_similarity = (train_class_distribution - test_class_distribution).abs().sum()\n",
    "    print(\"\\nClass Distribution Similarity Score:\", class_distribution_similarity)\n",
    "\n",
    "    return class_distribution_similarity\n",
    "\n",
    "# Update the train_model function to include imputation\n",
    "def train_model(df, year):\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    teams_df_train = df[df['year'] < year]\n",
    "    teams_df_test = df[df['year'] == year]\n",
    "\n",
    "    X_train = teams_df_train.drop(\"playoff\", axis=1)  # Features\n",
    "    y_train = teams_df_train[\"playoff\"]  # Target variable\n",
    "\n",
    "    X_test = teams_df_test.drop(\"playoff\", axis=1)  # Features\n",
    "    y_test = teams_df_test[\"playoff\"]  # Target variable\n",
    "\n",
    "    print(f\"\\nTrain/Test size for year={year}:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# create a final dataset with the predictions: team, playoff, prediction (a probability between 0 and 1)\n",
    "def create_predictions(df, year, model, distribution_similarity=True):\n",
    "    # Create a copy of the original dataset\n",
    "    new_df = df.copy()\n",
    "\n",
    "    X_train, y_train, X_test, y_test = train_model(new_df, year)\n",
    "\n",
    "    # Check if the class distribution is similar between the training and test sets\n",
    "    if distribution_similarity:\n",
    "        calculate_class_distribution_similarity(new_df, y_train, y_test)    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test) # Predictions\n",
    "    y_pred_proba = model.predict_proba(X_test) # Prediction probabilities\n",
    "\n",
    "    # Calculate the AUC\n",
    "    auc = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "    print(f\"\\nAUC for year={year}:\", auc)\n",
    " \n",
    "    # Only add predictions to the test set\n",
    "    new_df.loc[new_df['year'] == year, 'prediction'] = y_pred\n",
    "    new_df.loc[new_df['year'] == year, 'prediction_proba'] = y_pred_proba[:,1]\n",
    "\n",
    "    # Filter the dataset to only include the year we are interested in\n",
    "    new_df = new_df[new_df['year'] == year]\n",
    "\n",
    "    # Convert the predictions to integers\n",
    "    new_df['prediction'] = new_df['prediction'].astype(int)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "min_year = df['year'].min() + 1\n",
    "max_year = df['year'].max()\n",
    "\n",
    "print(\"Min year:\", min_year, \"\\nMax year:\", max_year)\n",
    "\n",
    "\n",
    "def create_final_predictions(df, year):\n",
    "    # Select the best 4 teams for each conference (confID) ensuring unique teams\n",
    "    final_predictions = df[df['year'] == year].sort_values(by='prediction_proba', ascending=False).drop_duplicates(subset='tmID').groupby('confID').head(4)\n",
    "\n",
    "    # remove confID column\n",
    "    final_predictions.drop(['year', 'playoff', 'confID'], axis=1, inplace=True)\n",
    "\n",
    "    return final_predictions\n",
    "\n",
    "# Usage of the function within the loop\n",
    "for i in range(min_year, max_year + 1):\n",
    "    new_df = create_predictions(df, i, model, distribution_similarity=False)\n",
    "    new_df = create_final_predictions(new_df, i)\n",
    "    new_df.drop(new_df.columns.difference(['tmID', 'confID', 'year', 'playoff', 'prediction', 'prediction_proba']), axis=1, inplace=True)\n",
    "    new_df.to_csv(f\"../data/predictions/predictions_{i}.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
