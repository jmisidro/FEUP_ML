{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean/teams.csv\")\n",
    "\n",
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "df[\"playoff\"] = df[\"playoff\"].map({\"Y\": 1, \"N\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical(df, col):\n",
    "    values = df[col].unique()\n",
    "    mapping = {value: i for i, value in enumerate(values)}\n",
    "    df[col] = df[col].map(mapping)\n",
    "    return df\n",
    "\n",
    "df.fillna(-1, inplace=True)\n",
    "df = process_categorical(df, \"tmID\")\n",
    "df = process_categorical(df, \"confID\")\n",
    "df = process_categorical(df, \"firstRound\")\n",
    "df = process_categorical(df, \"semis\")\n",
    "df = process_categorical(df, \"finals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min year: 2 \n",
      "Max year: 10\n",
      "\n",
      "Train/Test size for year=2: (16, 48) (16, 48) (16,) (16,)\n",
      "\n",
      "year = 2, Accuracy: 1.0\n",
      "\n",
      "year = 2, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "\n",
      "year = 2, Confusion Matrix:\n",
      " [[8 0]\n",
      " [0 8]]\n",
      "\n",
      "Train/Test size for year=3: (32, 48) (16, 48) (32,) (16,)\n",
      "\n",
      "year = 3, Accuracy: 1.0\n",
      "\n",
      "year = 3, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "\n",
      "year = 3, Confusion Matrix:\n",
      " [[8 0]\n",
      " [0 8]]\n",
      "\n",
      "Train/Test size for year=4: (48, 48) (14, 48) (48,) (14,)\n",
      "\n",
      "year = 4, Accuracy: 1.0\n",
      "\n",
      "year = 4, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        14\n",
      "   macro avg       1.00      1.00      1.00        14\n",
      "weighted avg       1.00      1.00      1.00        14\n",
      "\n",
      "\n",
      "year = 4, Confusion Matrix:\n",
      " [[6 0]\n",
      " [0 8]]\n",
      "\n",
      "Train/Test size for year=5: (62, 48) (13, 48) (62,) (13,)\n",
      "\n",
      "year = 5, Accuracy: 1.0\n",
      "\n",
      "year = 5, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n",
      "\n",
      "year = 5, Confusion Matrix:\n",
      " [[5 0]\n",
      " [0 8]]\n",
      "\n",
      "Train/Test size for year=6: (75, 48) (13, 48) (75,) (13,)\n",
      "\n",
      "year = 6, Accuracy: 1.0\n",
      "\n",
      "year = 6, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n",
      "\n",
      "year = 6, Confusion Matrix:\n",
      " [[5 0]\n",
      " [0 8]]\n",
      "\n",
      "Train/Test size for year=7: (88, 48) (14, 48) (88,) (14,)\n",
      "\n",
      "year = 7, Accuracy: 1.0\n",
      "\n",
      "year = 7, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        14\n",
      "   macro avg       1.00      1.00      1.00        14\n",
      "weighted avg       1.00      1.00      1.00        14\n",
      "\n",
      "\n",
      "year = 7, Confusion Matrix:\n",
      " [[6 0]\n",
      " [0 8]]\n",
      "\n",
      "Train/Test size for year=8: (102, 48) (13, 48) (102,) (13,)\n",
      "\n",
      "year = 8, Accuracy: 1.0\n",
      "\n",
      "year = 8, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n",
      "\n",
      "year = 8, Confusion Matrix:\n",
      " [[5 0]\n",
      " [0 8]]\n",
      "\n",
      "Train/Test size for year=9: (115, 48) (14, 48) (115,) (14,)\n",
      "\n",
      "year = 9, Accuracy: 1.0\n",
      "\n",
      "year = 9, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        14\n",
      "   macro avg       1.00      1.00      1.00        14\n",
      "weighted avg       1.00      1.00      1.00        14\n",
      "\n",
      "\n",
      "year = 9, Confusion Matrix:\n",
      " [[6 0]\n",
      " [0 8]]\n",
      "\n",
      "Train/Test size for year=10: (129, 48) (13, 48) (129,) (13,)\n",
      "\n",
      "year = 10, Accuracy: 1.0\n",
      "\n",
      "year = 10, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n",
      "\n",
      "year = 10, Confusion Matrix:\n",
      " [[5 0]\n",
      " [0 8]]\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "min_year = 2\n",
    "max_year = df['year'].max()\n",
    "\n",
    "print(\"Min year:\", min_year, \"\\nMax year:\", max_year)\n",
    "\n",
    "for i in range(min_year, max_year + 1):\n",
    "    teams_df_train = df[df['year'] < i]\n",
    "    teams_df_test = df[df['year'] == i]\n",
    "\n",
    "    X_train = teams_df_train.drop(\"playoff\", axis=1) # Features\n",
    "    y_train = teams_df_train[\"playoff\"] # Target variable\n",
    "\n",
    "    X_test = teams_df_test.drop(\"playoff\", axis=1) # Features\n",
    "    y_test = teams_df_test[\"playoff\"] # Target variable\n",
    "\n",
    "    print(f\"\\nTrain/Test size for year={i}:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nyear = {i}, Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(f\"\\nyear = {i}, Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(f\"\\nyear = {i}, Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
