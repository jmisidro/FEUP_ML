{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean/teams.csv\")\n",
    "\n",
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "df[\"playoff\"] = df[\"playoff\"].map({\"Y\": 1, \"N\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_df(df):\n",
    "    le = LabelEncoder()\n",
    "    for col, col_type in df.dtypes.items():\n",
    "        if col_type == 'object' or col_type == 'datetime64[ns]':\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "df = encode_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min year: 2 \n",
      "Max year: 10\n",
      "\n",
      "Train/Test size for year=2: (777, 110) (882, 110) (777,) (882,)\n",
      "\n",
      "year = 2, Accuracy: 1.0\n",
      "\n",
      "year = 2, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00       882\n",
      "   macro avg       1.00      1.00      1.00       882\n",
      "weighted avg       1.00      1.00      1.00       882\n",
      "\n",
      "\n",
      "year = 2, Confusion Matrix:\n",
      " [[882]]\n",
      "\n",
      "Train/Test size for year=3: (1659, 110) (742, 110) (1659,) (742,)\n",
      "\n",
      "year = 3, Accuracy: 1.0\n",
      "\n",
      "year = 3, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       742\n",
      "\n",
      "    accuracy                           1.00       742\n",
      "   macro avg       1.00      1.00      1.00       742\n",
      "weighted avg       1.00      1.00      1.00       742\n",
      "\n",
      "\n",
      "year = 3, Confusion Matrix:\n",
      " [[742]]\n",
      "\n",
      "Train/Test size for year=4: (2401, 110) (728, 110) (2401,) (728,)\n",
      "\n",
      "year = 4, Accuracy: 1.0\n",
      "\n",
      "year = 4, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       728\n",
      "\n",
      "    accuracy                           1.00       728\n",
      "   macro avg       1.00      1.00      1.00       728\n",
      "weighted avg       1.00      1.00      1.00       728\n",
      "\n",
      "\n",
      "year = 4, Confusion Matrix:\n",
      " [[728]]\n",
      "\n",
      "Train/Test size for year=5: (3129, 110) (959, 110) (3129,) (959,)\n",
      "\n",
      "year = 5, Accuracy: 1.0\n",
      "\n",
      "year = 5, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       959\n",
      "\n",
      "    accuracy                           1.00       959\n",
      "   macro avg       1.00      1.00      1.00       959\n",
      "weighted avg       1.00      1.00      1.00       959\n",
      "\n",
      "\n",
      "year = 5, Confusion Matrix:\n",
      " [[959]]\n",
      "\n",
      "Train/Test size for year=6: (4088, 110) (847, 110) (4088,) (847,)\n",
      "\n",
      "year = 6, Accuracy: 1.0\n",
      "\n",
      "year = 6, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       847\n",
      "\n",
      "    accuracy                           1.00       847\n",
      "   macro avg       1.00      1.00      1.00       847\n",
      "weighted avg       1.00      1.00      1.00       847\n",
      "\n",
      "\n",
      "year = 6, Confusion Matrix:\n",
      " [[847]]\n",
      "\n",
      "Train/Test size for year=7: (4935, 110) (714, 110) (4935,) (714,)\n",
      "\n",
      "year = 7, Accuracy: 1.0\n",
      "\n",
      "year = 7, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       714\n",
      "\n",
      "    accuracy                           1.00       714\n",
      "   macro avg       1.00      1.00      1.00       714\n",
      "weighted avg       1.00      1.00      1.00       714\n",
      "\n",
      "\n",
      "year = 7, Confusion Matrix:\n",
      " [[714]]\n",
      "\n",
      "Train/Test size for year=8: (5649, 110) (714, 110) (5649,) (714,)\n",
      "\n",
      "year = 8, Accuracy: 1.0\n",
      "\n",
      "year = 8, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       714\n",
      "\n",
      "    accuracy                           1.00       714\n",
      "   macro avg       1.00      1.00      1.00       714\n",
      "weighted avg       1.00      1.00      1.00       714\n",
      "\n",
      "\n",
      "year = 8, Confusion Matrix:\n",
      " [[714]]\n",
      "\n",
      "Train/Test size for year=9: (6363, 110) (791, 110) (6363,) (791,)\n",
      "\n",
      "year = 9, Accuracy: 1.0\n",
      "\n",
      "year = 9, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       791\n",
      "\n",
      "    accuracy                           1.00       791\n",
      "   macro avg       1.00      1.00      1.00       791\n",
      "weighted avg       1.00      1.00      1.00       791\n",
      "\n",
      "\n",
      "year = 9, Confusion Matrix:\n",
      " [[791]]\n",
      "\n",
      "Train/Test size for year=10: (7154, 110) (840, 110) (7154,) (840,)\n",
      "\n",
      "year = 10, Accuracy: 1.0\n",
      "\n",
      "year = 10, Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       840\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "\n",
      "year = 10, Confusion Matrix:\n",
      " [[840]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "min_year = 2\n",
    "max_year = df['year'].max()\n",
    "\n",
    "print(\"Min year:\", min_year, \"\\nMax year:\", max_year)\n",
    "\n",
    "for i in range(min_year, max_year + 1):\n",
    "    teams_df_train = df[df['year'] < i]\n",
    "    teams_df_test = df[df['year'] == i]\n",
    "\n",
    "    X_train = teams_df_train.drop(\"playoff\", axis=1) # Features\n",
    "    y_train = teams_df_train[\"playoff\"] # Target variable\n",
    "\n",
    "    X_test = teams_df_test.drop(\"playoff\", axis=1) # Features\n",
    "    y_test = teams_df_test[\"playoff\"] # Target variable\n",
    "\n",
    "    print(f\"\\nTrain/Test size for year={i}:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "    # Step 1: Calculate class distribution in the original dataset\n",
    "    original_class_distribution = df['playoff'].value_counts(normalize=True)\n",
    "    print(\"Original Class Distribution:\")\n",
    "    print(original_class_distribution)\n",
    "\n",
    "    # Step 2: Calculate class distribution in the training and test sets\n",
    "    train_class_distribution = y_train.value_counts(normalize=True)\n",
    "    test_class_distribution = y_test.value_counts(normalize=True)\n",
    "\n",
    "    print(\"\\nTraining Set Class Distribution:\")\n",
    "    print(train_class_distribution)\n",
    "    print(\"\\nTest Set Class Distribution:\")\n",
    "    print(test_class_distribution)\n",
    "\n",
    "    # Step 3: Compare class distributions\n",
    "    class_distribution_similarity = (train_class_distribution - test_class_distribution).abs().sum()\n",
    "    print(\"\\nClass Distribution Similarity Score:\", class_distribution_similarity)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nyear = {i}, Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(f\"\\nyear = {i}, Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(f\"\\nyear = {i}, Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
