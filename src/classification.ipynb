{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../data/clean/merged.csv\")\n",
    "df = pd.read_csv(\"../data/clean/teams.csv\") # TESTING\n",
    "\n",
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "df[\"playoff\"] = df[\"playoff\"].map({\"Y\": 1, \"N\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tmID</th>\n",
       "      <th>confID</th>\n",
       "      <th>rank</th>\n",
       "      <th>playoff</th>\n",
       "      <th>firstRound</th>\n",
       "      <th>semis</th>\n",
       "      <th>finals</th>\n",
       "      <th>o_fga</th>\n",
       "      <th>o_fta</th>\n",
       "      <th>...</th>\n",
       "      <th>d_pts</th>\n",
       "      <th>won</th>\n",
       "      <th>lost</th>\n",
       "      <th>GP</th>\n",
       "      <th>homeW</th>\n",
       "      <th>homeL</th>\n",
       "      <th>awayW</th>\n",
       "      <th>awayL</th>\n",
       "      <th>confW</th>\n",
       "      <th>confL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2258</td>\n",
       "      <td>725</td>\n",
       "      <td>...</td>\n",
       "      <td>2879</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2428</td>\n",
       "      <td>755</td>\n",
       "      <td>...</td>\n",
       "      <td>2797</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1903</td>\n",
       "      <td>577</td>\n",
       "      <td>...</td>\n",
       "      <td>2429</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1780</td>\n",
       "      <td>528</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1790</td>\n",
       "      <td>663</td>\n",
       "      <td>...</td>\n",
       "      <td>2133</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  tmID  confID  rank  playoff  firstRound  semis  finals  o_fga  o_fta  \\\n",
       "0     9     0       0     7        0           2      2       2   2258    725   \n",
       "1    10     0       0     2        1           0      2       2   2428    755   \n",
       "2     1     1       0     8        0           2      2       2   1903    577   \n",
       "3     2     1       0     4        1           1      1       0   1780    528   \n",
       "4     3     1       0     2        1           0      2       2   1790    663   \n",
       "\n",
       "   ...  d_pts  won  lost  GP  homeW  homeL  awayW  awayL  confW  confL  \n",
       "0  ...   2879    4    30  34      1     16      3     14      2     18  \n",
       "1  ...   2797   18    16  34     12      5      6     11     10     12  \n",
       "2  ...   2429    8    24  32      5     11      3     13      5     16  \n",
       "3  ...   2009   18    14  32     11      5      7      9     15      6  \n",
       "4  ...   2133   18    14  32     11      5      7      9     12      9  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_df(df):\n",
    "    le = LabelEncoder()\n",
    "    for col, col_type in df.dtypes.items():\n",
    "        if col_type == 'object' or col_type == 'datetime64[ns]':\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "df = encode_df(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min year: 2 \n",
      "Max year: 10\n",
      "\n",
      "Train/Test size for year=2: (16, 36) (16, 36) (16,) (16,)\n",
      "\n",
      "AUC for year=2: 0.90625\n",
      "\n",
      "Train/Test size for year=3: (32, 36) (16, 36) (32,) (16,)\n",
      "\n",
      "AUC for year=3: 0.953125\n",
      "\n",
      "Train/Test size for year=4: (48, 36) (14, 36) (48,) (14,)\n",
      "\n",
      "AUC for year=4: 0.7291666666666666\n",
      "\n",
      "Train/Test size for year=5: (62, 36) (13, 36) (62,) (13,)\n",
      "\n",
      "AUC for year=5: 0.8\n",
      "\n",
      "Train/Test size for year=6: (75, 36) (13, 36) (75,) (13,)\n",
      "\n",
      "AUC for year=6: 0.85\n",
      "\n",
      "Train/Test size for year=7: (88, 36) (14, 36) (88,) (14,)\n",
      "\n",
      "AUC for year=7: 1.0\n",
      "\n",
      "Train/Test size for year=8: (102, 36) (13, 36) (102,) (13,)\n",
      "\n",
      "AUC for year=8: 1.0\n",
      "\n",
      "Train/Test size for year=9: (115, 36) (14, 36) (115,) (14,)\n",
      "\n",
      "AUC for year=9: 0.9375\n",
      "\n",
      "Train/Test size for year=10: (129, 36) (13, 36) (129,) (13,)\n",
      "\n",
      "AUC for year=10: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_distribution_similarity(df, y_train, y_test):\n",
    "    # Step 1: Calculate class distribution in the original dataset\n",
    "    original_class_distribution = df['playoff'].value_counts(normalize=True)\n",
    "    print(\"Original Class Distribution:\")\n",
    "    print(original_class_distribution)\n",
    "\n",
    "    # Step 2: Calculate class distribution in the training and test sets\n",
    "    train_class_distribution = y_train.value_counts(normalize=True)\n",
    "    test_class_distribution = y_test.value_counts(normalize=True)\n",
    "\n",
    "    print(\"\\nTraining Set Class Distribution:\")\n",
    "    print(train_class_distribution)\n",
    "    print(\"\\nTest Set Class Distribution:\")\n",
    "    print(test_class_distribution)\n",
    "\n",
    "    # Step 3: Compare class distributions\n",
    "    class_distribution_similarity = (train_class_distribution - test_class_distribution).abs().sum()\n",
    "    print(\"\\nClass Distribution Similarity Score:\", class_distribution_similarity)\n",
    "\n",
    "    return class_distribution_similarity\n",
    "\n",
    "# Update the train_model function to include imputation\n",
    "def train_model(df, year):\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    teams_df_train = df[df['year'] < year]\n",
    "    teams_df_test = df[df['year'] == year]\n",
    "\n",
    "    X_train = teams_df_train.drop(\"playoff\", axis=1)  # Features\n",
    "    y_train = teams_df_train[\"playoff\"]  # Target variable\n",
    "\n",
    "    X_test = teams_df_test.drop(\"playoff\", axis=1)  # Features\n",
    "    y_test = teams_df_test[\"playoff\"]  # Target variable\n",
    "\n",
    "    print(f\"\\nTrain/Test size for year={year}:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# create a final dataset with the predictions: team, playoff, prediction (a probability between 0 and 1)\n",
    "def create_predictions(df, year, model, distribution_similarity=True):\n",
    "    # Create a copy of the original dataset\n",
    "    new_df = df.copy()\n",
    "\n",
    "    X_train, y_train, X_test, y_test = train_model(new_df, year)\n",
    "\n",
    "    # Check if the class distribution is similar between the training and test sets\n",
    "    if distribution_similarity:\n",
    "        calculate_class_distribution_similarity(new_df, y_train, y_test)    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test) # Predictions\n",
    "    y_pred_proba = model.predict_proba(X_test) # Prediction probabilities\n",
    "\n",
    "    # Calculate the AUC\n",
    "    auc = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "    print(f\"\\nAUC for year={year}:\", auc)\n",
    " \n",
    "    # Only add predictions to the test set\n",
    "    new_df.loc[new_df['year'] == year, 'prediction'] = y_pred\n",
    "    new_df.loc[new_df['year'] == year, 'prediction_proba'] = y_pred_proba[:,1]\n",
    "\n",
    "    # Filter the dataset to only include the year we are interested in\n",
    "    new_df = new_df[new_df['year'] == year]\n",
    "\n",
    "    # Convert the predictions to integers\n",
    "    new_df['prediction'] = new_df['prediction'].astype(int)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "min_year = df['year'].min() + 1\n",
    "max_year = df['year'].max()\n",
    "\n",
    "print(\"Min year:\", min_year, \"\\nMax year:\", max_year)\n",
    "\n",
    "\n",
    "def create_final_predictions(df, year):\n",
    "    # Select the best 4 teams for each conference (confID)\n",
    "    final_predictions = df[df['year'] == year].sort_values(by='prediction_proba', ascending=False).groupby('confID').head(4)\n",
    "    return final_predictions\n",
    "\n",
    "# Usage of the function within the loop\n",
    "for i in range(min_year, max_year + 1):\n",
    "    new_df = create_predictions(df, i, model, distribution_similarity=False)\n",
    "    new_df = create_final_predictions(new_df, i)\n",
    "    new_df.drop(new_df.columns.difference(['tmID', 'confID', 'year', 'playoff', 'prediction', 'prediction_proba']), axis=1, inplace=True)\n",
    "    new_df.to_csv(f\"../data/predictions/predictions_{i}.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
