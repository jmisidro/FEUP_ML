{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>confID</th>\n",
       "      <th>playoff</th>\n",
       "      <th>last_year_rank</th>\n",
       "      <th>last_year_o_fga</th>\n",
       "      <th>last_year_o_fta</th>\n",
       "      <th>last_year_o_3pa</th>\n",
       "      <th>last_year_o_reb</th>\n",
       "      <th>last_year_o_asts</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_team_last_year_allPF</th>\n",
       "      <th>avg_team_last_year_allFGA</th>\n",
       "      <th>avg_team_last_year_allTR</th>\n",
       "      <th>avg_team_last_year_allTRA</th>\n",
       "      <th>avg_team_last_year_allMinutes</th>\n",
       "      <th>num_players_joined</th>\n",
       "      <th>num_players_left</th>\n",
       "      <th>num_players_changed_team</th>\n",
       "      <th>award_points_coach</th>\n",
       "      <th>last_year_mean_wins_coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>9</td>\n",
       "      <td>EA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2079.8</td>\n",
       "      <td>640.9</td>\n",
       "      <td>502.7</td>\n",
       "      <td>1077.6</td>\n",
       "      <td>520.7</td>\n",
       "      <td>...</td>\n",
       "      <td>55.259615</td>\n",
       "      <td>166.201122</td>\n",
       "      <td>17.840144</td>\n",
       "      <td>49.144631</td>\n",
       "      <td>510.537660</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.026701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.361367</td>\n",
       "      <td>169.501920</td>\n",
       "      <td>17.682412</td>\n",
       "      <td>55.124040</td>\n",
       "      <td>526.865207</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>11</td>\n",
       "      <td>EA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2428.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.603550</td>\n",
       "      <td>203.643491</td>\n",
       "      <td>12.802515</td>\n",
       "      <td>41.376479</td>\n",
       "      <td>638.306213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHA</td>\n",
       "      <td>1</td>\n",
       "      <td>EA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.676768</td>\n",
       "      <td>178.505051</td>\n",
       "      <td>16.609091</td>\n",
       "      <td>49.047475</td>\n",
       "      <td>574.079798</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHA</td>\n",
       "      <td>2</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.366267</td>\n",
       "      <td>198.638224</td>\n",
       "      <td>21.541417</td>\n",
       "      <td>62.973054</td>\n",
       "      <td>686.959581</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tmID  year confID  playoff  last_year_rank  last_year_o_fga  \\\n",
       "0  ATL     9     EA      0.0             3.5           2079.8   \n",
       "1  ATL    10     EA      1.0             7.0           2258.0   \n",
       "2  ATL    11     EA      NaN             2.0           2428.0   \n",
       "3  CHA     1     EA      0.0             0.0              0.0   \n",
       "4  CHA     2     EA      1.0             8.0           1903.0   \n",
       "\n",
       "   last_year_o_fta  last_year_o_3pa  last_year_o_reb  last_year_o_asts  ...  \\\n",
       "0            640.9            502.7           1077.6             520.7  ...   \n",
       "1            725.0            598.0           1077.0             492.0  ...   \n",
       "2            755.0            374.0           1259.0             547.0  ...   \n",
       "3              0.0              0.0              0.0               0.0  ...   \n",
       "4            577.0            386.0            935.0             551.0  ...   \n",
       "\n",
       "   avg_team_last_year_allPF  avg_team_last_year_allFGA  \\\n",
       "0                 55.259615                 166.201122   \n",
       "1                 54.361367                 169.501920   \n",
       "2                 56.603550                 203.643491   \n",
       "3                 54.676768                 178.505051   \n",
       "4                 70.366267                 198.638224   \n",
       "\n",
       "   avg_team_last_year_allTR  avg_team_last_year_allTRA  \\\n",
       "0                 17.840144                  49.144631   \n",
       "1                 17.682412                  55.124040   \n",
       "2                 12.802515                  41.376479   \n",
       "3                 16.609091                  49.047475   \n",
       "4                 21.541417                  62.973054   \n",
       "\n",
       "   avg_team_last_year_allMinutes  num_players_joined  num_players_left  \\\n",
       "0                     510.537660                14.0               9.0   \n",
       "1                     526.865207                 8.0              13.0   \n",
       "2                     638.306213                 0.0               0.0   \n",
       "3                     574.079798                13.0               8.0   \n",
       "4                     686.959581                 7.0               3.0   \n",
       "\n",
       "   num_players_changed_team  award_points_coach  last_year_mean_wins_coach  \n",
       "0                      23.0                 0.0                   1.026701  \n",
       "1                      21.0                 1.0                   0.133333  \n",
       "2                       0.0                 0.0                   1.000000  \n",
       "3                      21.0                 0.0                   0.000000  \n",
       "4                      10.0                 0.0                   0.391304  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/clean/merged.csv\")\n",
    "\n",
    "# Convert \"playoff\" column to binary (Y: 1, N: 0)\n",
    "df[\"playoff\"] = df[\"playoff\"].map({\"Y\": 1, \"N\": 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_year(data, test_year):\n",
    "    train_set = data[(data['year'] < test_year)]\n",
    "    test_set = data[data['year'] == test_year]\n",
    "    return train_set, test_set\n",
    "\n",
    "def evaluate_model(model, train_set_original, test_set_original):\n",
    "    \n",
    "    train_set = train_set_original.copy()\n",
    "    test_set = test_set_original.copy()\n",
    "\n",
    "    \n",
    "    tmIDs = test_set['tmID']\n",
    "    confIDs = test_set['confID']\n",
    "    train_set.drop(['tmID', 'confID', 'year'], axis=1, inplace=True)\n",
    "    test_set.drop(['tmID', 'confID', 'year'], axis=1, inplace=True)\n",
    "    \n",
    "    X_train, y_train = train_set.drop(columns=['playoff']), train_set['playoff']\n",
    "    X_test, y_test = test_set.drop(columns=['playoff']), test_set['playoff']\n",
    "\n",
    "    # Initialize SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    \n",
    "    # Fit SMOTE on the training data\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.astype(int)\n",
    "    \n",
    "    predict_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Normalize predict_proba to ensure the sum is 8\n",
    "    predict_proba = 8 * (predict_proba / predict_proba.sum())\n",
    "        \n",
    "    results = pd.DataFrame({\n",
    "        'tmID' : tmIDs,\n",
    "        'confID': confIDs,\n",
    "        'playoff' : y_pred,\n",
    "        'predict_proba' : predict_proba\n",
    "    })\n",
    "\n",
    "    # Remove duplicates\n",
    "    results = results.drop_duplicates(subset='tmID', keep='first')\n",
    "    \n",
    "    # Ensure that the top 4 teams from each conference are selected --> playoff = 1\n",
    "    top4 = results.sort_values(by='predict_proba', ascending=False).groupby('confID').head(4)\n",
    "    # Update the top 4 teams to playoff = 1 in results\n",
    "    results.loc[results['tmID'].isin(top4['tmID']), 'playoff'] = 1\n",
    "\n",
    "    # Update the rest of the teams to playoff = 0 in results\n",
    "    results.loc[~results['tmID'].isin(top4['tmID']), 'playoff'] = 0\n",
    "\n",
    "    # Remove predict_proba column\n",
    "    results.drop(columns=['predict_proba'], inplace=True)\n",
    "\n",
    "    \n",
    "    # Select the best 4 teams for each conference (confID) ensuring unique teams\n",
    "    #results = results.sort_values(by='predict_proba', ascending=False).groupby('confID').head(4)\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, test_year, model):\n",
    "    train_data, test_data = train_test_split_by_year(data, test_year)\n",
    "    result = evaluate_model(model, train_data, test_data)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m }\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m results\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfID\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/predictions/predictions_11.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data, test_year, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(data, test_year, model):\n\u001b[1;32m      2\u001b[0m     train_data, test_data \u001b[38;5;241m=\u001b[39m train_test_split_by_year(data, test_year)\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[51], line 46\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, train_set_original, test_set_original)\u001b[0m\n\u001b[1;32m     43\u001b[0m results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmID\u001b[39m\u001b[38;5;124m'\u001b[39m, keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Ensure that the top 4 teams from each conference are selected --> playoff = 1\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m top4 \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict_proba\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Update the top 4 teams to playoff = 1 in results\u001b[39;00m\n\u001b[1;32m     48\u001b[0m results\u001b[38;5;241m.\u001b[39mloc[results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(top4[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmID\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayoff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/core/frame.py:7189\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7183\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m lexsort_indexer(\n\u001b[1;32m   7184\u001b[0m         keys, orders\u001b[38;5;241m=\u001b[39mascending, na_position\u001b[38;5;241m=\u001b[39mna_position, key\u001b[38;5;241m=\u001b[39mkey\n\u001b[1;32m   7185\u001b[0m     )\n\u001b[1;32m   7186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(by):\n\u001b[1;32m   7187\u001b[0m     \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[0;32m-> 7189\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7191\u001b[0m     \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[1;32m   7192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   7193\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m   7194\u001b[0m         \u001b[38;5;66;03m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/core/generic.py:1911\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predict_proba'"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_iter': 1000\n",
    "}\n",
    "\n",
    "results = train_model(df, 11, LogisticRegression(**params))\n",
    "\n",
    "results.drop(['confID'], axis=1, inplace=True)\n",
    "results.to_csv(f\"../data/predictions/predictions_11.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
